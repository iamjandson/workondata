{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kRzWAU5ltL_A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7b9253f2-7a43-4941-ebd4-bdd1976ab13f","executionInfo":{"status":"ok","timestamp":1566047910357,"user_tz":180,"elapsed":179663,"user":{"displayName":"JANDSON SILVA","photoUrl":"https://lh5.googleusercontent.com/-jG98cDsx7C8/AAAAAAAAAAI/AAAAAAAAAAc/60BqUKPreGg/s64/photo.jpg","userId":"12402138018959733697"}}},"source":["import matplotlib.pyplot as plt\n","from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","batch_size =  128\n","num_classes = 10\n","epochs = 12\n","img_rows, img_cols = 32, 32\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","input_shape = (32,32,3)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),  activation='relu',input_shape=input_shape))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=input_shape))\n","model.add(Dropout(0.25))  \n","\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape) )\n","model.add(Conv2D(1024, (3, 3), activation='relu', input_shape=input_shape) )\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(64, activation='relu') )  \n","model.add(Flatten() )\n","model.add(Dense(num_classes, activation='softmax') )\n","\n"," \n","model.summary()\n","\n","model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'] )\n","\n","dados = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test) )\n"," \n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","dados.history.keys()\n","plt.plot(dados.history['val_loss'], color='lightblue', linewidth=3)\n","plt.plot(dados.history['val_acc'])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["W0817 13:15:29.370863 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0817 13:15:29.378011 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0817 13:15:29.413383 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0817 13:15:29.421516 140121715849088 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0817 13:15:29.435816 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0817 13:15:29.524557 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0817 13:15:29.531866 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 1024)      1180672   \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 1024)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 5, 5, 1024)        0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5, 5, 64)          65600     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                16010     \n","=================================================================\n","Total params: 1,355,530\n","Trainable params: 1,355,530\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["W0817 13:15:29.641550 140121715849088 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/12\n","50000/50000 [==============================] - 21s 418us/step - loss: 1.9162 - acc: 0.3045 - val_loss: 1.6281 - val_acc: 0.4310\n","Epoch 2/12\n","50000/50000 [==============================] - 14s 277us/step - loss: 1.4389 - acc: 0.4851 - val_loss: 1.3619 - val_acc: 0.5196\n","Epoch 3/12\n","50000/50000 [==============================] - 14s 278us/step - loss: 1.2182 - acc: 0.5720 - val_loss: 1.2798 - val_acc: 0.5427\n","Epoch 4/12\n","50000/50000 [==============================] - 14s 281us/step - loss: 1.0519 - acc: 0.6324 - val_loss: 0.9871 - val_acc: 0.6620\n","Epoch 5/12\n","50000/50000 [==============================] - 14s 282us/step - loss: 0.9276 - acc: 0.6776 - val_loss: 0.9705 - val_acc: 0.6639\n","Epoch 6/12\n","50000/50000 [==============================] - 14s 285us/step - loss: 0.8265 - acc: 0.7119 - val_loss: 0.8435 - val_acc: 0.7063\n","Epoch 7/12\n","50000/50000 [==============================] - 14s 285us/step - loss: 0.7463 - acc: 0.7388 - val_loss: 0.7819 - val_acc: 0.7286\n","Epoch 8/12\n","50000/50000 [==============================] - 14s 283us/step - loss: 0.6720 - acc: 0.7642 - val_loss: 0.6885 - val_acc: 0.7650\n","Epoch 9/12\n","50000/50000 [==============================] - 14s 283us/step - loss: 0.6105 - acc: 0.7890 - val_loss: 0.8942 - val_acc: 0.7052\n","Epoch 10/12\n","50000/50000 [==============================] - 14s 282us/step - loss: 0.5587 - acc: 0.8068 - val_loss: 0.7128 - val_acc: 0.7527\n","Epoch 11/12\n","50000/50000 [==============================] - 14s 282us/step - loss: 0.5151 - acc: 0.8185 - val_loss: 0.7375 - val_acc: 0.7513\n","Epoch 12/12\n","50000/50000 [==============================] - 14s 283us/step - loss: 0.4636 - acc: 0.8370 - val_loss: 0.7379 - val_acc: 0.7493\n","Test loss: 0.7379212761878967\n","Test accuracy: 0.7493\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f704a416c10>]"]},"metadata":{"tags":[]},"execution_count":2},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"j7UPIQCkvHyO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9f99c082-3697-47d4-ae49-4a84480ae577","executionInfo":{"status":"error","timestamp":1566050046548,"user_tz":180,"elapsed":1883533,"user":{"displayName":"JANDSON SILVA","photoUrl":"https://lh5.googleusercontent.com/-jG98cDsx7C8/AAAAAAAAAAI/AAAAAAAAAAc/60BqUKPreGg/s64/photo.jpg","userId":"12402138018959733697"}}},"source":["import keras\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.datasets import cifar10\n","from keras import regularizers\n","from keras.callbacks import LearningRateScheduler\n","import numpy as np\n"," \n","def lr_schedule(epoch):\n","    lrate = 0.001\n","    if epoch > 75:\n","        lrate = 0.0005\n","    if epoch > 100:\n","        lrate = 0.0003\n","    return lrate\n"," \n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n"," \n","#z-score\n","mean = np.mean(x_train,axis=(0,1,2,3))\n","std = np.std(x_train,axis=(0,1,2,3))\n","x_train = (x_train-mean)/(std+1e-7)\n","x_test = (x_test-mean)/(std+1e-7)\n"," \n","num_classes = 10\n","y_train = np_utils.to_categorical(y_train,num_classes)\n","y_test = np_utils.to_categorical(y_test,num_classes)\n"," \n","weight_decay = 1e-4\n","model = Sequential()\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n"," \n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.3))\n"," \n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.4))\n"," \n","model.add(Flatten())\n","model.add(Dense(num_classes, activation='softmax'))\n"," \n","model.summary()\n"," \n","#data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    )\n","datagen.fit(x_train)\n"," \n","#training\n","batch_size = 64\n"," \n","opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n","model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n","model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n","                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n","                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n","#save to disk\n","model_json = model.to_json()\n","with open('model.json', 'w') as json_file:\n","    json_file.write(model_json)\n","model.save_weights('model.h5') \n"," \n","#testing\n","#scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n","#print('Test result: %.3f loss: %.3f' % (scores[1]*100,scores[0])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["W0817 13:22:42.577646 140121715849088 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                20490     \n","=================================================================\n","Total params: 309,290\n","Trainable params: 308,394\n","Non-trainable params: 896\n","_________________________________________________________________\n","Epoch 1/125\n","781/781 [==============================] - 26s 33ms/step - loss: 1.9186 - acc: 0.4248 - val_loss: 1.5757 - val_acc: 0.5394\n","Epoch 2/125\n","781/781 [==============================] - 24s 31ms/step - loss: 1.2935 - acc: 0.5843 - val_loss: 1.1541 - val_acc: 0.6474\n","Epoch 3/125\n","781/781 [==============================] - 24s 31ms/step - loss: 1.0855 - acc: 0.6529 - val_loss: 1.2570 - val_acc: 0.6435\n","Epoch 4/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.9769 - acc: 0.6950 - val_loss: 0.8363 - val_acc: 0.7488\n","Epoch 5/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.9113 - acc: 0.7174 - val_loss: 0.8479 - val_acc: 0.7548\n","Epoch 6/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.8644 - acc: 0.7375 - val_loss: 0.8907 - val_acc: 0.7533\n","Epoch 7/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.8307 - acc: 0.7477 - val_loss: 0.6836 - val_acc: 0.8007\n","Epoch 8/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.8064 - acc: 0.7611 - val_loss: 0.8908 - val_acc: 0.7509\n","Epoch 9/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7837 - acc: 0.7664 - val_loss: 0.7541 - val_acc: 0.7865\n","Epoch 10/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7606 - acc: 0.7777 - val_loss: 0.7721 - val_acc: 0.7867\n","Epoch 11/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7447 - acc: 0.7834 - val_loss: 0.7704 - val_acc: 0.7869\n","Epoch 12/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7323 - acc: 0.7875 - val_loss: 0.7600 - val_acc: 0.7898\n","Epoch 13/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7213 - acc: 0.7940 - val_loss: 0.7761 - val_acc: 0.7930\n","Epoch 14/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.7092 - acc: 0.7985 - val_loss: 0.6534 - val_acc: 0.8220\n","Epoch 15/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6968 - acc: 0.8040 - val_loss: 0.6432 - val_acc: 0.8312\n","Epoch 16/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6878 - acc: 0.8072 - val_loss: 0.6897 - val_acc: 0.8164\n","Epoch 17/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6823 - acc: 0.8106 - val_loss: 0.6193 - val_acc: 0.8347\n","Epoch 18/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6767 - acc: 0.8133 - val_loss: 0.6700 - val_acc: 0.8226\n","Epoch 19/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6700 - acc: 0.8158 - val_loss: 0.6543 - val_acc: 0.8261\n","Epoch 20/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6690 - acc: 0.8179 - val_loss: 0.6804 - val_acc: 0.8243\n","Epoch 21/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6627 - acc: 0.8189 - val_loss: 0.7227 - val_acc: 0.8068\n","Epoch 22/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6533 - acc: 0.8228 - val_loss: 0.6595 - val_acc: 0.8266\n","Epoch 23/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6553 - acc: 0.8231 - val_loss: 0.6569 - val_acc: 0.8275\n","Epoch 24/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6495 - acc: 0.8243 - val_loss: 0.6514 - val_acc: 0.8310\n","Epoch 25/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6467 - acc: 0.8258 - val_loss: 0.6436 - val_acc: 0.8302\n","Epoch 26/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6418 - acc: 0.8284 - val_loss: 0.6052 - val_acc: 0.8439\n","Epoch 27/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6376 - acc: 0.8289 - val_loss: 0.5989 - val_acc: 0.8461\n","Epoch 28/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6348 - acc: 0.8322 - val_loss: 0.6809 - val_acc: 0.8229\n","Epoch 29/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6326 - acc: 0.8315 - val_loss: 0.6466 - val_acc: 0.8343\n","Epoch 30/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6335 - acc: 0.8335 - val_loss: 0.6518 - val_acc: 0.8341\n","Epoch 31/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6293 - acc: 0.8340 - val_loss: 0.6145 - val_acc: 0.8472\n","Epoch 32/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6261 - acc: 0.8333 - val_loss: 0.6115 - val_acc: 0.8469\n","Epoch 33/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6198 - acc: 0.8359 - val_loss: 0.6181 - val_acc: 0.8437\n","Epoch 34/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6201 - acc: 0.8374 - val_loss: 0.6380 - val_acc: 0.8411\n","Epoch 35/125\n","781/781 [==============================] - 24s 30ms/step - loss: 0.6193 - acc: 0.8380 - val_loss: 0.6339 - val_acc: 0.8442\n","Epoch 36/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6213 - acc: 0.8368 - val_loss: 0.6160 - val_acc: 0.8402\n","Epoch 37/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6107 - acc: 0.8421 - val_loss: 0.5792 - val_acc: 0.8573\n","Epoch 38/125\n","781/781 [==============================] - 24s 30ms/step - loss: 0.6181 - acc: 0.8400 - val_loss: 0.6132 - val_acc: 0.8451\n","Epoch 39/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6125 - acc: 0.8423 - val_loss: 0.6345 - val_acc: 0.8408\n","Epoch 40/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6081 - acc: 0.8423 - val_loss: 0.5976 - val_acc: 0.8483\n","Epoch 41/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6086 - acc: 0.8430 - val_loss: 0.5997 - val_acc: 0.8536\n","Epoch 42/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6117 - acc: 0.8398 - val_loss: 0.5979 - val_acc: 0.8517\n","Epoch 43/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.6096 - acc: 0.8410 - val_loss: 0.6085 - val_acc: 0.8456\n","Epoch 44/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6072 - acc: 0.8444 - val_loss: 0.6117 - val_acc: 0.8471\n","Epoch 45/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.6030 - acc: 0.8431 - val_loss: 0.6027 - val_acc: 0.8479\n","Epoch 46/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5972 - acc: 0.8467 - val_loss: 0.6324 - val_acc: 0.8450\n","Epoch 47/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5997 - acc: 0.8475 - val_loss: 0.6619 - val_acc: 0.8394\n","Epoch 48/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6029 - acc: 0.8443 - val_loss: 0.5819 - val_acc: 0.8583\n","Epoch 49/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.6037 - acc: 0.8431 - val_loss: 0.5737 - val_acc: 0.8573\n","Epoch 50/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5895 - acc: 0.8502 - val_loss: 0.6046 - val_acc: 0.8473\n","Epoch 51/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.6008 - acc: 0.8444 - val_loss: 0.5819 - val_acc: 0.8543\n","Epoch 52/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5936 - acc: 0.8486 - val_loss: 0.6333 - val_acc: 0.8419\n","Epoch 53/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5986 - acc: 0.8473 - val_loss: 0.6033 - val_acc: 0.8510\n","Epoch 54/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5950 - acc: 0.8479 - val_loss: 0.7179 - val_acc: 0.8219\n","Epoch 55/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5913 - acc: 0.8482 - val_loss: 0.5625 - val_acc: 0.8655\n","Epoch 56/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5909 - acc: 0.8493 - val_loss: 0.6242 - val_acc: 0.8437\n","Epoch 57/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5921 - acc: 0.8492 - val_loss: 0.5886 - val_acc: 0.8582\n","Epoch 58/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5879 - acc: 0.8501 - val_loss: 0.5904 - val_acc: 0.8556\n","Epoch 59/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5886 - acc: 0.8515 - val_loss: 0.6256 - val_acc: 0.8443\n","Epoch 60/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5877 - acc: 0.8494 - val_loss: 0.5902 - val_acc: 0.8538\n","Epoch 61/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5879 - acc: 0.8522 - val_loss: 0.5959 - val_acc: 0.8542\n","Epoch 62/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5835 - acc: 0.8520 - val_loss: 0.5659 - val_acc: 0.8617\n","Epoch 63/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5825 - acc: 0.8523 - val_loss: 0.6379 - val_acc: 0.8393\n","Epoch 64/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5817 - acc: 0.8527 - val_loss: 0.6365 - val_acc: 0.8427\n","Epoch 65/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5857 - acc: 0.8515 - val_loss: 0.5725 - val_acc: 0.8568\n","Epoch 66/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5823 - acc: 0.8516 - val_loss: 0.6453 - val_acc: 0.8445\n","Epoch 67/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5792 - acc: 0.8534 - val_loss: 0.5713 - val_acc: 0.8635\n","Epoch 68/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5810 - acc: 0.8531 - val_loss: 0.6254 - val_acc: 0.8467\n","Epoch 69/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5801 - acc: 0.8534 - val_loss: 0.5694 - val_acc: 0.8598\n","Epoch 70/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5797 - acc: 0.8520 - val_loss: 0.5491 - val_acc: 0.8692\n","Epoch 71/125\n","781/781 [==============================] - 25s 32ms/step - loss: 0.5761 - acc: 0.8542 - val_loss: 0.5937 - val_acc: 0.8569\n","Epoch 72/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5804 - acc: 0.8535 - val_loss: 0.5745 - val_acc: 0.8615\n","Epoch 73/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5770 - acc: 0.8543 - val_loss: 0.5847 - val_acc: 0.8580\n","Epoch 74/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5753 - acc: 0.8565 - val_loss: 0.6530 - val_acc: 0.8353\n","Epoch 75/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5726 - acc: 0.8553 - val_loss: 0.5858 - val_acc: 0.8610\n","Epoch 76/125\n","781/781 [==============================] - 25s 31ms/step - loss: 0.5758 - acc: 0.8552 - val_loss: 0.5884 - val_acc: 0.8573\n","Epoch 77/125\n","781/781 [==============================] - 24s 31ms/step - loss: 0.5284 - acc: 0.8699 - val_loss: 0.5522 - val_acc: 0.8646\n","Epoch 78/125\n","213/781 [=======>......................] - ETA: 16s - loss: 0.5196 - acc: 0.8730"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-5-e33c604f0612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mopt_rms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmsprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_rms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;31m#save to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"pbbAeP112ZzW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8207377b-2a91-4141-96db-5a72725dc558","executionInfo":{"status":"ok","timestamp":1566062391182,"user_tz":180,"elapsed":321186,"user":{"displayName":"JANDSON SILVA","photoUrl":"https://lh5.googleusercontent.com/-jG98cDsx7C8/AAAAAAAAAAI/AAAAAAAAAAc/60BqUKPreGg/s64/photo.jpg","userId":"12402138018959733697"}}},"source":["import keras\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.datasets import cifar10\n","from keras import regularizers\n","from keras.callbacks import LearningRateScheduler\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n"," \n","def lr_schedule(epoch):\n","    lrate = 0.001\n","    if epoch > 75:\n","        lrate = 0.0005\n","    if epoch > 100:\n","        lrate = 0.0003\n","    return lrate\n"," \n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n"," \n","#z-score\n","mean = np.mean(x_train,axis=(0,1,2,3))\n","std = np.std(x_train,axis=(0,1,2,3))\n","x_train = (x_train-mean)/(std+1e-7)\n","x_test = (x_test-mean)/(std+1e-7)\n"," \n","num_classes = 10\n","y_train = np_utils.to_categorical(y_train,num_classes)\n","y_test = np_utils.to_categorical(y_test,num_classes)\n"," \n","weight_decay = 1e-4\n","model = Sequential()\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n"," \n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.3))\n"," \n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.4))\n"," \n","model.add(Flatten())\n","model.add(Dense(num_classes, activation='softmax'))\n"," \n","model.summary()\n"," \n","#data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    )\n","datagen.fit(x_train)\n"," \n","#training\n","batch_size = 64\n"," \n","opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n","model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n","model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n","                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=12,\\\n","                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n","#save to disk\n","model_json = model.to_json()\n","with open('model.json', 'w') as json_file:\n","    json_file.write(model_json)\n","model.save_weights('model.h5') \n"," \n","#testing\n","#scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n","#print('Test result: %.3f loss: %.3f' % (scores[1]*100,scores[0])\n","\n","dados.history.keys()\n","plt.plot(dados.history['val_loss'], color='lightblue', linewidth=3)\n","plt.plot(dados.history['val_acc'])\n","\n","previsoes =  model.predict(x_test)\n","y_test_matriz = [np.argmax(t) for t in y_test]\n","y_previsoes_matriz = [np.argmax(t) for i in previsoes]\n","confusao = confusion_matrix(y_test_matriz, y_previsoes_matriz)\n","\n","y_train [20]\n","novo = x_train [20]\n","novo = np.expand_dims(novo, axis=0)\n","pred = model.predict(novo)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_77 (Conv2D)           (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_73 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","batch_normalization_73 (Batc (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","conv2d_78 (Conv2D)           (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_74 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","batch_normalization_74 (Batc (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_39 (MaxPooling (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","dropout_39 (Dropout)         (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_79 (Conv2D)           (None, 16, 16, 64)        18496     \n","_________________________________________________________________\n","activation_75 (Activation)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","batch_normalization_75 (Batc (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","conv2d_80 (Conv2D)           (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","activation_76 (Activation)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","batch_normalization_76 (Batc (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_40 (MaxPooling (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_40 (Dropout)         (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_81 (Conv2D)           (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","activation_77 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","batch_normalization_77 (Batc (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","conv2d_82 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_78 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","batch_normalization_78 (Batc (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","max_pooling2d_41 (MaxPooling (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_41 (Dropout)         (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 2048)              0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 10)                20490     \n","=================================================================\n","Total params: 309,290\n","Trainable params: 308,394\n","Non-trainable params: 896\n","_________________________________________________________________\n","Epoch 1/12\n","781/781 [==============================] - 31s 40ms/step - loss: 1.8962 - acc: 0.4272 - val_loss: 1.3842 - val_acc: 0.5728\n","Epoch 2/12\n","781/781 [==============================] - 25s 32ms/step - loss: 1.3003 - acc: 0.5969 - val_loss: 1.4156 - val_acc: 0.5951\n","Epoch 3/12\n","781/781 [==============================] - 25s 33ms/step - loss: 1.1120 - acc: 0.6534 - val_loss: 0.9756 - val_acc: 0.6986\n","Epoch 4/12\n","781/781 [==============================] - 25s 32ms/step - loss: 1.0114 - acc: 0.6879 - val_loss: 0.9571 - val_acc: 0.7163\n","Epoch 5/12\n","781/781 [==============================] - 25s 33ms/step - loss: 0.9384 - acc: 0.7120 - val_loss: 1.0123 - val_acc: 0.7114\n","Epoch 6/12\n","781/781 [==============================] - 25s 33ms/step - loss: 0.8920 - acc: 0.7316 - val_loss: 0.8953 - val_acc: 0.7435\n","Epoch 7/12\n","781/781 [==============================] - 25s 32ms/step - loss: 0.8493 - acc: 0.7444 - val_loss: 0.8161 - val_acc: 0.7607\n","Epoch 8/12\n","781/781 [==============================] - 25s 32ms/step - loss: 0.8284 - acc: 0.7525 - val_loss: 0.9017 - val_acc: 0.7498\n","Epoch 9/12\n","781/781 [==============================] - 25s 33ms/step - loss: 0.7966 - acc: 0.7642 - val_loss: 0.7908 - val_acc: 0.7770\n","Epoch 10/12\n","781/781 [==============================] - 26s 33ms/step - loss: 0.7826 - acc: 0.7714 - val_loss: 0.7021 - val_acc: 0.8036\n","Epoch 11/12\n","781/781 [==============================] - 25s 32ms/step - loss: 0.7608 - acc: 0.7804 - val_loss: 0.8022 - val_acc: 0.7851\n","Epoch 12/12\n","781/781 [==============================] - 25s 33ms/step - loss: 0.7518 - acc: 0.7833 - val_loss: 0.8037 - val_acc: 0.7906\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}